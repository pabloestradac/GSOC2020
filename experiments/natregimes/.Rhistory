mean(5)
string <- "log(M)"
gsub("log", "", string) # Works just fine
grep("log", "", string) # Works just fine
grep("[a-z]", letters)
txt <- c("arm","foot","lefroo", "bafoobar")
if(length(i <- grep("foo", txt)))
cat("'foo' appears at least once in\n\t", txt, "\n")
i # 2 and 4
txt[i]
grep("foo", txt)
if(length(i <- grep("foo", txt)))
cat("'foo' appears at least once in\n\t", txt, "\n")
txt <- c("log(M)","foot","lefroo", "bafoobar")
grep("log(", txt)
grep("log", txt)
# install.packages(c("data.table", "bibliometrix", "pastecs", "tidyverse", "fuzzyjoin", "parallel", "doParallel"))
# dir = "C:\\Users\\pablo\\OneDrive - Escuela Superior Politécnica del Litoral\\Decano_RA\\ScopusPapers2018\\scopus50"
setwd("/home/opc/scopus50")
# packrat::init()
# packrat::snapshot()
packrat::restore()
packrat::status()
start_time <- Sys.time()
library(data.table)
library(bibliometrix)
library(pastecs)
library(dplyr)
library(fuzzyjoin)
library(parallel)
library(doParallel)
# Section 1: Data Processing ----------------------------------------------
D.scopus <- readFiles("query1.bib",
"query2.bib",
"query3.bib")
dir = "C:\\Users\\pablo\\OneDrive - Escuela Superior Politécnica del Litoral\\Decano_RA\\ScopusPapers2018\\scopus50"
start_time <- Sys.time()
library(data.table)
library(bibliometrix)
library(pastecs)
library(dplyr)
library(fuzzyjoin)
library(parallel)
library(doParallel)
D.scopus <- readFiles("query1.bib",
"query2.bib",
"query3.bib")
library(data.table)
D.scopus <- readFiles("query1.bib",
"query2.bib",
"query3.bib")
dir = "C:\\Users\\pablo\\OneDrive - Escuela Superior Politécnica del Litoral\\Decano_RA\\ScopusPapers2018\\scopus50"
library(data.table)
library(bibliometrix)
library(pastecs)
library(dplyr)
library(fuzzyjoin)
library(parallel)
library(doParallel)
D.scopus <- readFiles("query1.bib",
"query2.bib",
"query3.bib")
# install.packages(c("data.table", "bibliometrix", "pastecs", "tidyverse", "fuzzyjoin", "parallel", "doParallel"))
dir = "C:\\Users\\pablo\\OneDrive - Escuela Superior Politécnica del Litoral\\Decano_RA\\ScopusPapers2018\\scopus50"
start_time <- Sys.time()
library(data.table)
library(bibliometrix)
library(pastecs)
library(dplyr)
library(fuzzyjoin)
library(parallel)
library(doParallel)
# Section 1: Data Processing ----------------------------------------------
D.scopus <- readFiles("query1.bib",
"query2.bib",
"query3.bib")
install.packages(c("data.table", "bibliometrix", "pastecs", "tidyverse", "fuzzyjoin", "parallel", "doParallel"))
# installing/loading the package:
if(!require(installr)) {
install.packages("installr");
require(installr)
} #load / install+load installr
# using the package:
updateR()
# using the package:
updateR()
install.packages(c("copula", "np"))
# using kernel method to fit joint density and copula density
# If you haven't done so, install the packages first
# install.packages('np')
# install.packages('copula')
library('np')
library('copula')
par(mfrow=c(2,2))
persp(normalCopula(.5), dcopula,main='Normal Copula (rho=0.5)')
help("Defunct")
persp(normalCopula(.5), dCopula,main='Normal Copula (rho=0.5)')
persp(frankCopula(3.5),dCopula,main='Frank Copula (rho=0.5)')
persp(claytonCopula(1.1),dCopula,main='Clayton Copula (rho=.5)')
persp(gumbelCopula(1.55),dCopula,main='Gumbel Copula (rho=.5)')
persp(normalCopula(.5), dCopula, main='Normal Copula (rho=0.5)')
persp(frankCopula(3.5), dCopula, main='Frank Copula (rho=0.5)')
persp(claytonCopula(1.1), dCopula, main='Clayton Copula (rho=.5)')
persp(gumbelCopula(1.55), dCopula, main='Gumbel Copula (rho=.5)')
x=rnorm(200)
y=rnorm(200)/10+exp(x)/100
bwx=npudensbw(x)
normalCopula(.5), dCopula, main='Normal Copula (rho=0.5)'
persp(normalCopula(.5), dCopula, main='Normal Copula (rho=0.5)')
par(mfrow=c(1,1))
persp(normalCopula(.5), dCopula, main='Normal Copula (rho=0.5)')
persp(claytonCopula(1.1), dCopula, main='Clayton Copula (rho=.5)')
e_x=seq(min(x),max(x),length=50) # for plotting
e_denx=fitted(npudens(bws=bwx,edat=e_x))
plot(e_denx)
plot(e_x, e_denx)
# different bandwidth for distributions
# alternatively, one can use empirical cdf
bwx2=npudistbw(x)
e_distx=fitted(npudist(bws=bwx2,edat=e_x))
plot(e_x, e_distx)
distx=fitted(npudist(bws=bwx2))
bwy=npudensbw(y)
e_y=seq(min(y),max(y),length=50)
e_deny=fitted(npudens(bws=bwy,edat=e_y))
plot(e_y, e_deny)
bwy2=npudistbw(y)
e_disty=fitted(npudist(bws=bwy2,edat=e_y))
disty=fitted(npudist(bws=bwy2))
plot(e_y, e_disty)
bwxy=npudensbw(formula=~distx+disty)
e_distxy=expand.grid(distx=e_distx,disty=e_disty)
e_c=fitted(npudens(bws=bwxy,edat=e_distxy))
e_denxy=expand.grid(e_denx,e_deny)
dd=e_c*e_denxy[,1]*e_denxy[,2]
dim(dd)
par(mfrow=c(1,1))
ddd=matrix(dd,50,50)
dim(ddd)
persp(e_x,e_y,ddd)
persp(e_distx,e_disty,matrix(e_c,50,50),zlim=c(0,2))
bw2=npudensbw(formula=~x+y)
npplot(bw2)
x=rnorm(2000)
y=rnorm(2000)/10+exp(x)/100
bwx=npudensbw(x)
e_x=seq(min(x),max(x),length=50) # for plotting
e_denx=fitted(npudens(bws=bwx,edat=e_x))
# different bandwidth for distributions
# alternatively, one can use empirical cdf
bwx2=npudistbw(x)
e_distx=fitted(npudist(bws=bwx2,edat=e_x))
distx=fitted(npudist(bws=bwx2))
bwy=npudensbw(y)
e_y=seq(min(y),max(y),length=50)
e_deny=fitted(npudens(bws=bwy,edat=e_y))
bwy2=npudistbw(y)
e_disty=fitted(npudist(bws=bwy2,edat=e_y))
disty=fitted(npudist(bws=bwy2))
bwxy=npudensbw(formula=~distx+disty)
e_distxy=expand.grid(distx=e_distx,disty=e_disty)
e_c=fitted(npudens(bws=bwxy,edat=e_distxy))
e_denxy=expand.grid(e_denx,e_deny)
dd=e_c*e_denxy[,1]*e_denxy[,2]
par(mfrow=c(1,1))
ddd=matrix(dd,50,50)
persp(e_x,e_y,ddd)
persp(e_distx,e_disty,matrix(e_c,50,50),zlim=c(0,2))
bw2=npudensbw(formula=~x+y)
x=rnorm(1000)
y=rnorm(1000)/10+exp(x)/100
bwx=npudensbw(x)
e_x=seq(min(x),max(x),length=50) # for plotting
e_denx=fitted(npudens(bws=bwx,edat=e_x))
# different bandwidth for distributions
# alternatively, one can use empirical cdf
bwx2=npudistbw(x)
e_distx=fitted(npudist(bws=bwx2,edat=e_x))
distx=fitted(npudist(bws=bwx2))
bwy=npudensbw(y)
e_y=seq(min(y),max(y),length=50)
e_deny=fitted(npudens(bws=bwy,edat=e_y))
bwy2=npudistbw(y)
e_disty=fitted(npudist(bws=bwy2,edat=e_y))
disty=fitted(npudist(bws=bwy2))
bwxy=npudensbw(formula=~distx+disty)
e_distxy=expand.grid(distx=e_distx,disty=e_disty)
e_c=fitted(npudens(bws=bwxy,edat=e_distxy))
e_denxy=expand.grid(e_denx,e_deny)
dd=e_c*e_denxy[,1]*e_denxy[,2]
par(mfrow=c(1,1))
ddd=matrix(dd,50,50)
persp(e_x,e_y,ddd)
persp(e_distx,e_disty,matrix(e_c,50,50),zlim=c(0,2))
bw2=npudensbw(formula=~x+y)
# double the bandwidth of copula
bwxy0=bwxy
bwxy$bw=bwxy$bw*2
e_distxy=expand.grid(distx=e_distx,disty=e_disty)
e_c=fitted(npudens(bws=bwxy,edat=e_distxy))
e_denxy=expand.grid(e_denx,e_deny)
dd=e_c*e_denxy[,1]*e_denxy[,2]
ddd=matrix(dd,50,50)
persp(e_x,e_y,ddd)
persp()
x=faithful[,1]
y=faithful[,2]
bwxy=npudensbw(formula=~x+y)
plot(bwxy)
n=length(x)
u=rank(x)/(n+1)
v=rank(y)/(n+1)
bwuv=npudensbw(formula=~u+v)
plot(bwuv)
s=qnorm(u)
t=qnorm(v)
bwst=npudensbw(formula=~s+t)
u0=v0=seq(.02,.98,.02)
uv0=expand.grid(u0,v0)
st0=expand.grid(qnorm(u0),qnorm(v0))
dst0=fitted(npudens(bws=bwst,edat=st0))
contour(qnorm(u0),qnorm(v0),matrix(dst0,49,49))
persp(qnorm(u0),qnorm(v0),matrix(dst0,49,49))
dst=expand.grid(dnorm(qnorm(u0)),dnorm(qnorm(v0)))
dst=matrix(dst[,1]*dst[,2],49,49)
duv0=matrix(dst0,49,49)/dst
persp((u0),(v0),duv0)
contour(u0,v0,duv0,50)
# kernel regression (local constant)
data(cars)
attach(cars)
plot(speed,dist)
fit0=lm(dist~speed)
plot(fit0)
library('np')
bw=npregbw(dist~speed)
fit.k=npreg(bw)
bw
plot(speed,fit.k$mean,type='l')
points(speed,dist)
# local polynomial can be fitted using the 'loess' command
fit.lo=loess(dist~speed)
plot(fit.lo$x,fitted(fit.lo),type='l')
matplot(speed,cbind(fit.k$mean,fitted(fit.lo)),type='l')
points(speed,dist)
k=function(x,h) {1/h/sqrt(2*pi)*exp(-x^2/2/h^2)}
# rule of thumb bandwidth
n=length(speed)
h_r=sd(speed)*n^(-1/5)
# evaluate kernel predictions at sample points
y_fit=matrix(0,ncol=1,nrow=n)
for (i in 1:n)
{
fx=k(speed-speed[i],h_r)
y_fit[i]=mean(fx*dist)/mean(fx)
}
plot(speed,y_fit,type='b')
points(speed,dist)
fit.lo
h_r
# use ls cross validation
# simple grid search to find optimal bandwidth
# b=seq(h_r/5,h_r*5,length=50)
b=seq(1.5,1.8,length=50)
lscv=matrix(0,ncol=1,nrow=50)
for (j in 1:50)
{
h=b[j]
# calculate the leave out one density
out_i=matrix(0,ncol=1,nrow=n)
for (i in 1:n)
{
speed_i=speed[-i]
dist_i=dist[-i]
fx_i=k(speed_i-speed[i],h)
out_i[i]=mean(fx_i*dist_i)/mean(fx_i)
}
lscv[j]=mean((dist-out_i)^2)
}
plot(b,lscv,type='b')
b[lscv==min(lscv)]
b=seq(h_r/3,h_r*3,length=50)
# b=seq(1.5,1.8,length=50)
lscv=matrix(0,ncol=1,nrow=50)
for (j in 1:50)
{
h=b[j]
# calculate the leave out one density
out_i=matrix(0,ncol=1,nrow=n)
for (i in 1:n)
{
speed_i=speed[-i]
dist_i=dist[-i]
fx_i=k(speed_i-speed[i],h)
out_i[i]=mean(fx_i*dist_i)/mean(fx_i)
}
lscv[j]=mean((dist-out_i)^2)
}
plot(b,lscv,type='b')
# find the bandwdith that minimizes the lscv
b[lscv==min(lscv)]
b=seq(1.5,1.8,length=50)
lscv=matrix(0,ncol=1,nrow=50)
for (j in 1:50)
{
h=b[j]
# calculate the leave out one density
out_i=matrix(0,ncol=1,nrow=n)
for (i in 1:n)
{
speed_i=speed[-i]
dist_i=dist[-i]
fx_i=k(speed_i-speed[i],h)
out_i[i]=mean(fx_i*dist_i)/mean(fx_i)
}
lscv[j]=mean((dist-out_i)^2)
}
plot(b,lscv,type='b')
# find the bandwdith that minimizes the lscv
b[lscv==min(lscv)]
n_b = 100
b=seq(1.5,1.8,length=n_b)
lscv=matrix(0,ncol=1,nrow=n_b)
for (j in 1:n_b)
{
h=b[j]
# calculate the leave out one density
out_i=matrix(0,ncol=1,nrow=n)
for (i in 1:n)
{
speed_i=speed[-i]
dist_i=dist[-i]
fx_i=k(speed_i-speed[i],h)
out_i[i]=mean(fx_i*dist_i)/mean(fx_i)
}
lscv[j]=mean((dist-out_i)^2)
}
plot(b,lscv,type='b')
# find the bandwdith that minimizes the lscv
b[lscv==min(lscv)]
# find optimal bandwidht using numerical optimization
# lscv objective function
q_h=function(h)
{
out_i=matrix(0,ncol=1,nrow=n)
for (i in 1:n)
{
speed_i=speed[-i]
dist_i=dist[-i]
fx_i=k(speed_i-speed[i],h)
out_i[i]=mean(fx_i*dist_i)/mean(fx_i)
}
mean((dist-out_i)^2)
}
h_lscv=optim(h_r,q_h,method='L-BFGS-B',lower=h_r/5,upper=h_r*5)
h_lscv
library(splm)
library(data.table)
install.packages("data.table")
library(data.table)
remove.packages(data.table)
remove.packages("data.table")
install.packages(c("data.table", "splm"), dependencies = TRUE)
install.packages(c("data.table", "splm"), dependencies = TRUE)
library(data.table)
install.packages("data.table", dependencies=TRUE)
library(data.table)
install.packages("data.table", type = "binary")
library(data.table)
which R
install.packages("data.table", repos="https://Rdatatable.github.io/data.table")
library(data.table)
require(devtools)
install.packages("devtools")
install.packages("data.table", type="source")
library(data.table)
install.packages("data.table", repos="https://Rdatatable.github.io/data.table")
install.packages("rtools")
install.packages("installr")
library(installr)
updateR()
install.packages(c("data.table", "splm"))
library(splm)
library(data.table)
setwd("C:\\Users\\pablo\\OneDrive - Escuela Superior Politécnica del Litoral\\2 MECE\\Others\\GSoC\\GSOC2020\\scripts\\natregimes")
db <- st_read('natregimes.shp')
queen1 <- poly2nb(db)
W <- nb2listw(queen1)
db_reg <- melt(setDT(db), id="FIPSNO",
measure=patterns("^HR", "^RD", "^PS", "^UE"),
value.name = c("HR", "RD", "PS", "UE"), variable.name="YEAR")
fixed_lag = spml(HR ~ RD + PS, data=db_reg,index=c('FIPSNO','YEAR'),
listw=W, model="within", spatial.error="none", lag=TRUE)
summary(fixed_lag)
browser() breakpoints
browser()
splm
splm()
breakpoints
exit
debugSource('C:/Users/pablo/OneDrive - Escuela Superior Politécnica del Litoral/2 MECE/Others/GSoC/GSOC2020/scripts/splm_example.R', echo=TRUE)
HR
