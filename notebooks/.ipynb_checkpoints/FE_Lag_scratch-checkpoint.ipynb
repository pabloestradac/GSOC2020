{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Lag - Fixed Effects Panel Model\n",
    "\n",
    "This notebook introduces the Spatial Lag model for Fixed Effects Panel data. It is based on the estimation procedure outline in:\n",
    "- Anselin, Le Gallo and Jayet (2008). Spatial Panel Econometrics.\n",
    "- Elhorst (2014). Spatial Econometrics, From Cross-Sectional Data to Spatial Panels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal\n",
    "import spreg\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from scipy import sparse as sp\n",
    "from scipy.sparse.linalg import splu as SuperLU\n",
    "from spreg.utils import RegressionPropsY, RegressionPropsVM, inverse_prod, set_warn\n",
    "from spreg.sputils import spdot, spfill_diagonal, spinv\n",
    "import spreg.diagnostics as DIAG\n",
    "import spreg.user_output as USER\n",
    "import spreg.summary_output as SUMMARY\n",
    "try:\n",
    "    from scipy.optimize import minimize_scalar\n",
    "    minimize_scalar_available = True\n",
    "except ImportError:\n",
    "    minimize_scalar_available = False\n",
    "    \n",
    "from spreg.panel_utils import check_panel, demean_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data on NCOVR US County Homicides (3085 areas).\n",
    "nat = libpysal.examples.load_example(\"NCOVR\")\n",
    "db = libpysal.io.open(nat.get_path(\"NAT.dbf\"), \"r\")\n",
    "# Create spatial weight matrix\n",
    "nat_shp = libpysal.examples.get_path(\"NAT.shp\")\n",
    "w = libpysal.weights.Queen.from_shapefile(nat_shp)\n",
    "w.transform = 'r'\n",
    "# Define dependent variable\n",
    "name_y = [\"HR70\", \"HR80\", \"HR90\"]\n",
    "y = np.array([db.by_col(name) for name in name_y]).T\n",
    "# Define independent variables\n",
    "name_x = [\"RD70\", \"RD80\", \"RD90\", \"PS70\", \"PS80\", \"PS90\"]\n",
    "x = np.array([db.by_col(name) for name in name_x]).T\n",
    "\n",
    "epsilon = 0.0000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Assuming panel is in wide format, i.e. y[:, 0] refers to T0, y[:, 1] refers to T1, etc.\n",
      "Similarly, assuming x[:, 0:T] refers to T periods of k1, x[:, T+1:2T] refers to k2, etc.\n"
     ]
    }
   ],
   "source": [
    "# Check the data structure and converts from wide to long if needed.\n",
    "bigy, bigx, name_y, name_x = check_panel(y, x, w, name_y, name_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demeaning the variables using \n",
    "$$\n",
    "y^\\ast = Q_0 y\n",
    "$$ \n",
    "\n",
    "where $Q_0 = J_T \\otimes I_N$ and $J_T = I_T - \\iota \\cdot \\iota' / t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = w.n\n",
    "t = bigy.shape[0] // n\n",
    "k = bigx.shape[1]\n",
    "# Demeaned variables\n",
    "y = demean_panel(bigy, n, t)\n",
    "x = demean_panel(bigx, n, t)\n",
    "# Big W matrix\n",
    "W = w.full()[0]\n",
    "W_nt = np.kron(np.identity(t), W)\n",
    "Wsp = w.sparse\n",
    "Wsp_nt = sp.kron(sp.identity(t), Wsp)\n",
    "# Lag dependent variable\n",
    "ylag = spdot(W_nt, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'll compute the residuals of these two regressions:\n",
    "$$\n",
    "y = X\\beta_0 + e_0\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Wy = X\\beta_1 + e_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b0, b1, e0 and e1\n",
    "xtx = spdot(x.T, x)\n",
    "xtxi = la.inv(xtx)\n",
    "xty = spdot(x.T, y)\n",
    "xtyl = spdot(x.T, ylag)\n",
    "b0 = spdot(xtxi, xty)\n",
    "b1 = spdot(xtxi, xtyl)\n",
    "e0 = y - spdot(x, b0)\n",
    "e1 = ylag - spdot(x, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, maximize the concentrated log-likehood function with respect to $\\rho$:\n",
    "$$\n",
    "L = \\frac{NT}{2} \\ln (e'_r e_r) - T \\ln | I_N - \\rho W |\n",
    "$$\n",
    "\n",
    "where $e_r = e_0 - \\rho e_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_c_loglik_sp(rho, n, t, e0, e1, I, Wsp):\n",
    "    # concentrated log-lik for lag model, sparse algebra\n",
    "    if isinstance(rho, np.ndarray):\n",
    "        if rho.shape == (1, 1):\n",
    "            rho = rho[0][0]\n",
    "    er = e0 - rho * e1\n",
    "    sig2 = spdot(er.T, er) / (n*t)\n",
    "    nlsig2 = (n*t / 2.0) * np.log(sig2)\n",
    "    a = I - rho * Wsp\n",
    "    LU = SuperLU(a.tocsc())\n",
    "    jacob = t * np.sum(np.log(np.abs(LU.U.diagonal())))\n",
    "    clike = nlsig2 - jacob\n",
    "    return clike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1903042364374238"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = sp.identity(n)\n",
    "res = minimize_scalar(lag_c_loglik_sp, 0.0, bounds=(-1.0, 1.0),\n",
    "                      args=(n, t, e0, e1, I, Wsp), method='bounded',\n",
    "                      tol=epsilon)\n",
    "\n",
    "rho = res.x[0][0]\n",
    "rho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate betas as:\n",
    "$$\n",
    "\\beta = \\beta_o - \\rho \\beta_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80058859],\n",
       "       [-2.60035236],\n",
       "       [ 0.19030424]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b, residuals and predicted values\n",
    "b = b0 - rho * b1\n",
    "betas = np.vstack((b, rho))   # rho added as last coefficient\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $\\sigma^2$ as:\n",
    "$$\n",
    "\\sigma^2 = (e_0 - \\rho \\cdot e_1)' (e_0 - \\rho \\cdot e_1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute full log-likelihood, including constants\n",
    "ln2pi = np.log(2.0 * np.pi)\n",
    "llik = -res.fun - (n*t) / 2.0 * ln2pi - (n*t) / 2.0\n",
    "logll = llik[0][0]\n",
    "\n",
    "# Calculate sigma2\n",
    "u = e0 - rho * e1\n",
    "sig2 = spdot(u.T, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Var[\\beta, \\delta, \\sigma^2] = \n",
    "\\begin{pmatrix}\n",
    "\\frac{X'X}{\\sigma^2}               &                                               &  \\\\ \n",
    "X' (I_T \\otimes \\tilde{W}) X \\beta & T \\cdot tr(\\tilde{W}^2 + \\tilde{W}'\\tilde{W}) + \\beta' X' (I_T \\otimes \\tilde{W}'\\tilde{W}) X \\beta &  \\\\ \n",
    "0                                  & \\frac{T}{\\sigma^2} tr(\\tilde{W}) & \\frac{NT}{2 \\sigma^4} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "where $\\tilde{W} = W (I_N - \\rho W)^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predy = y - u\n",
    "xb = spdot(x, b)\n",
    "predy_e = inverse_prod(\n",
    "    Wsp_nt, xb, rho, inv_method=\"power_exp\", threshold=epsilon)\n",
    "e_pred = y - predy_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.41034357e+02,  2.02069853e+02, -7.48911836e-05],\n",
       "       [ 2.02069853e+02,  2.24784043e+03,  4.30066912e-04],\n",
       "       [-7.48911836e-05,  4.30066912e-04,  2.57894113e-04]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information matrix\n",
    "a = -rho * W\n",
    "spfill_diagonal(a, 1.0)\n",
    "ai = spinv(a)\n",
    "wai = spdot(W, ai)\n",
    "tr1 = wai.diagonal().sum() #same for sparse and dense\n",
    "\n",
    "wai2 = spdot(wai, wai)\n",
    "tr2 = wai2.diagonal().sum()\n",
    "\n",
    "waiTwai = spdot(wai.T, wai)\n",
    "tr3 = waiTwai.diagonal().sum()\n",
    "\n",
    "wai_nt = np.kron(np.identity(t), wai)\n",
    "wpredy = spdot(wai_nt, xb)\n",
    "xTwpy = spdot(x.T, wpredy)\n",
    "\n",
    "waiTwai_nt = np.kron(np.identity(t), waiTwai)\n",
    "wTwpredy = spdot(waiTwai_nt, xb)\n",
    "wpyTwpy = spdot(xb.T, wTwpredy)\n",
    "\n",
    "# order of variables is beta, rho, sigma2\n",
    "v1 = np.vstack(\n",
    "    (xtx / sig2, xTwpy.T / sig2, np.zeros((1, k))))\n",
    "v2 = np.vstack(\n",
    "    (xTwpy / sig2, t*(tr2 + tr3) + wpyTwpy / sig2, t * tr1 / sig2))\n",
    "v3 = np.vstack(\n",
    "    (np.zeros((k, 1)), t * tr1 / sig2, n * t / (2.0 * sig2 ** 2)))\n",
    "\n",
    "v = np.hstack((v1, v2, v3))\n",
    "\n",
    "vm1 = la.inv(v)  # vm1 includes variance for sigma2\n",
    "vm = vm1[:-1, :-1]  # vm is for coefficients only\n",
    "vm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load library\n",
    "library(\"splm\")\n",
    "\n",
    "### set options\n",
    "options(prompt = \"R> \",  continue = \"+ \", width = 70, useFancyQuotes = FALSE, warn=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data\n",
    "nat <- read.csv(\"NAT.csv\", header = TRUE)\n",
    "## set formula\n",
    "fm <- HR ~ RD + PS\n",
    "wnat <- as.matrix(read.csv(\"NAT_w.csv\"))\n",
    "## standardization\n",
    "wnat <- wnat/apply(wnat, 1, sum)\n",
    "## make it a listw\n",
    "lwnat <- mat2listw(wnat)\n",
    "\n",
    "col_order <- c(\"FIPSNO\", \"YEAR\", \"HR\", \"RD\", \"PS\")\n",
    "nat <- nat[, col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_lag = spml(HR ~ RD + PS, data=nat, listw=lwnat, effect=\"individual\",\n",
    "                 model=\"within\", spatial.error = \"b\", lag=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spatial panel fixed effects sarar model\n",
       " \n",
       "\n",
       "Call:\n",
       "spml(formula = HR ~ RD + PS, data = nat, listw = lwnat, model = \"within\", \n",
       "    effect = \"individual\", lag = TRUE, spatial.error = \"b\")\n",
       "\n",
       "Residuals:\n",
       "     Min.   1st Qu.    Median   3rd Qu.      Max. \n",
       "-32.45463  -2.14303  -0.16628   1.86690  68.14883 \n",
       "\n",
       "Spatial error parameter:\n",
       "    Estimate Std. Error t-value  Pr(>|t|)    \n",
       "rho 0.665193   0.016183  41.105 < 2.2e-16 ***\n",
       "\n",
       "Spatial autoregressive coefficient:\n",
       "        Estimate Std. Error t-value  Pr(>|t|)    \n",
       "lambda -0.637435   0.028888 -22.066 < 2.2e-16 ***\n",
       "\n",
       "Coefficients:\n",
       "   Estimate Std. Error t-value  Pr(>|t|)    \n",
       "RD  1.28071    0.14070  9.1024 < 2.2e-16 ***\n",
       "PS -3.06970    0.41822 -7.3400 2.137e-13 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(fixed_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
