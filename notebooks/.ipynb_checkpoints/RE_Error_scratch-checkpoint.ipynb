{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Error - Random Effects Panel Model\n",
    "\n",
    "This notebook introduces the Spatial Error model for Random Effects Panel data. It is based on the estimation procedure outline in:\n",
    "- Anselin, Le Gallo and Jayet (2008). Spatial Panel Econometrics.\n",
    "- Elhorst (2014). Spatial Econometrics, From Cross-Sectional Data to Spatial Panels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal\n",
    "import spreg\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from scipy import sparse as sp\n",
    "from scipy.sparse.linalg import splu as SuperLU\n",
    "from spreg.utils import RegressionPropsY, RegressionPropsVM, inverse_prod, set_warn\n",
    "from spreg.sputils import spdot, spfill_diagonal, spinv\n",
    "from spreg.w_utils import symmetrize\n",
    "import spreg.diagnostics as DIAG\n",
    "import spreg.user_output as USER\n",
    "import spreg.summary_output as SUMMARY\n",
    "try:\n",
    "    from scipy.optimize import minimize\n",
    "    minimize_scalar_available = True\n",
    "except ImportError:\n",
    "    minimize_scalar_available = False\n",
    "    \n",
    "from spreg.panel_utils import check_panel, demean_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal.weights import w_subset\n",
    "import pandas as pd\n",
    "# Open data on NCOVR US County Homicides (3085 areas).\n",
    "nat = libpysal.examples.load_example(\"NCOVR\")\n",
    "db = libpysal.io.open(nat.get_path(\"NAT.dbf\"), \"r\")\n",
    "# Create spatial weight matrix\n",
    "nat_shp = libpysal.examples.get_path(\"NAT.shp\")\n",
    "w_full = libpysal.weights.Queen.from_shapefile(nat_shp)\n",
    "\n",
    "# Define dependent variable\n",
    "name_y = [\"HR70\", \"HR80\", \"HR90\"]\n",
    "y_full = np.array([db.by_col(name) for name in name_y]).T\n",
    "# Define independent variables\n",
    "name_x = [\"RD70\", \"RD80\", \"RD90\", \"PS70\", \"PS80\", \"PS90\"]\n",
    "x_full = np.array([db.by_col(name) for name in name_x]).T\n",
    "\n",
    "epsilon = 0.0000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with a subset of the data, to get a faster implementation of the random effects estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ecdb96791edc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mname_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"STATE_NAME\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"FIPSNO\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_counties\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mby_col\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfilter_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Arkansas\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Kansas\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Missouri\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Oklahoma\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfilter_counties\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_counties\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_counties\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"STATE_NAME\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"FIPSNO\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "name_c = [\"STATE_NAME\", \"FIPSNO\"]\n",
    "df_counties = pd.DataFrame([db.by_col(name) for name in name_c], index=name_c).T\n",
    "\n",
    "filter_states = [\"Arkansas\", \"Kansas\", \"Missouri\", \"Oklahoma\"]\n",
    "filter_counties = df_counties[df_counties[\"STATE_NAME\"].isin(filter_states)][\"FIPSNO\"].values\n",
    "\n",
    "counties = np.array(db.by_col(\"FIPSNO\"))\n",
    "subid = np.where(np.isin(counties, filter_counties))[0]\n",
    "\n",
    "w = w_subset(w_full, subid)\n",
    "w.transform = 'r'\n",
    "\n",
    "y = y_full[subid, ]\n",
    "x = x_full[subid, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Assuming panel is in wide format, i.e. y[:, 0] refers to T0, y[:, 1] refers to T1, etc.\n",
      "Similarly, assuming x[:, 0:T] refers to T periods of k1, x[:, T+1:2T] refers to k2, etc.\n"
     ]
    }
   ],
   "source": [
    "# Check the data structure and conve rts from wide to long if needed.\n",
    "bigy, bigx, name_y, name_x = check_panel(y, x, w, name_y, name_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_x = [\"constant\", \"RD\", \"PS\"]\n",
    "ones = np.ones((bigx.shape[0], 1))\n",
    "bigx = np.hstack((ones, bigx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = w.n\n",
    "t = bigy.shape[0] // n\n",
    "k = bigx.shape[1]\n",
    "# Big W matrix\n",
    "W = w.full()[0]\n",
    "Wsp = w.sparse\n",
    "Wsp_nt = sp.kron(sp.identity(t), Wsp, format=\"csr\")\n",
    "# lag dependent variable\n",
    "ylag = spdot(Wsp_nt, bigy)\n",
    "xlag = spdot(Wsp_nt, bigx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concentrated log-likehood function with respect to $\\lambda$ and $\\phi$:\n",
    "$$\n",
    "L = \\frac{NT}{2} \\ln (e'_r e_r) + \\frac{1}{2} \\sum_i^N \\ln \\left[1 + T\\phi^2 (1 - \\lambda \\omega_i)^2 \\right] - T \\sum_i^N \\ln (1 - \\lambda \\omega_i)\n",
    "$$\n",
    "\n",
    "where $e_r = (I - \\lambda W)y + [P - (I - \\lambda W)] \\bar{y} - \\left[ (I - \\lambda W)X + [P - (I - \\lambda W)] \\bar{X} \\right] \\beta $.\n",
    "\n",
    "Also, $P$ is defined as:\n",
    "$$\n",
    "P = \\Lambda^{-1/2} R\n",
    "$$\n",
    "\n",
    "where $R = [v_1, v_2, ..., v_n]$ and $v_i$ is the characteristic vector $i$ of matrix $W$. And the $\\Lambda$ is a diagonal matrix with elements $c_i = T\\phi^2 + \\frac{1}{(1-\\lambda \\omega_i)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.identity(n)\n",
    "if w.asymmetry(intrinsic=False) == []:\n",
    "    ww = symmetrize(w)\n",
    "    WW = np.array(ww.todense())\n",
    "    evals, evecs = la.eigh(WW)\n",
    "    W = WW\n",
    "else:     # need dense here\n",
    "    evals, evecs = la.eig(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = np.ones((t, 1))\n",
    "J = (1/t)*spdot(one, one.T)\n",
    "Q = sp.kron(J, I, format=\"csr\")\n",
    "y_mean = spdot(Q, bigy)\n",
    "x_mean = spdot(Q, bigx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_c_loglik_ord(lam_phi, evals, evecs, n, t, bigy, bigx, ylag, xlag, y_mean, x_mean, I, W):\n",
    "    # concentrated log-lik for error model, no constants, eigenvalues \n",
    "    lam, phi = lam_phi\n",
    "    cvals = t*phi**2 + 1/(1-lam*evals)**2\n",
    "    P = spdot(np.diag(cvals**(-0.5)), evecs.T)\n",
    "    pr = P - (I - lam*W)\n",
    "    pr_nt = sp.kron(sp.identity(t), pr, format=\"csr\")\n",
    "    # Term 1\n",
    "    ys = bigy - lam * ylag\n",
    "    xs = bigx - lam * xlag\n",
    "    yp = ys + spdot(pr_nt, y_mean)\n",
    "    xp = xs + spdot(pr_nt, x_mean)\n",
    "    ypyp = np.dot(yp.T, yp)\n",
    "    xpxp = np.dot(xp.T, xp)\n",
    "    xpxpi = la.inv(xpxp)\n",
    "    xpyp = np.dot(xp.T, yp)\n",
    "    x1 = np.dot(xpxpi, xpyp)\n",
    "    x2 = np.dot(xpyp.T, x1)\n",
    "    ee = ypyp - x2\n",
    "    sig2 = ee[0][0]\n",
    "    nlsig2 = (n*t / 2.0) * np.log(sig2)\n",
    "    # Term 2\n",
    "    revals = t * phi**2 * (1 - lam*evals)**2\n",
    "    phi_jacob = 1/2 * np.log(1 + revals).sum()\n",
    "    # Term 3\n",
    "    jacob = t * np.log(1 - lam*evals).sum()\n",
    "    if isinstance(jacob, complex):\n",
    "        jacob = jacob.real\n",
    "    # this is the negative of the concentrated log lik for minimization\n",
    "    clik = nlsig2 + phi_jacob - jacob\n",
    "    return clik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(err_c_loglik_ord, (0.0, 0.1), \n",
    "               bounds=((-1.0, 1.0), (0.0, 10000.0)),\n",
    "               method='L-BFGS-B', \n",
    "               args=(evals, evecs, n, t, bigy, bigx, \n",
    "                     ylag, xlag, y_mean, x_mean, I, W))\n",
    "\n",
    "lam, phi = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 5601.382253326332\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-0.00045475,  0.0001819 ])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 36\n",
       "      nit: 7\n",
       "     njev: 12\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.32990395, 0.55707719])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3103349965606714"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3299039450893921"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.87843202],\n",
       "       [3.22715786],\n",
       "       [2.62990753]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate betas\n",
    "cvals = t*phi**2 + 1/(1-lam*evals)**2\n",
    "P = spdot(np.diag(cvals**(-0.5)), evecs.T)\n",
    "pr = P - (I - lam*W)\n",
    "pr_nt = sp.kron(sp.identity(t), pr, format=\"csr\")\n",
    "ys = bigy - lam * ylag\n",
    "xs = bigx - lam * xlag\n",
    "yp = ys + spdot(pr_nt, y_mean)\n",
    "xp = xs + spdot(pr_nt, x_mean)\n",
    "xpxp = np.dot(xp.T, xp)\n",
    "xpxpi = la.inv(xpxp)\n",
    "xpyp = np.dot(xp.T, yp)\n",
    "b = np.dot(xpxpi, xpyp)\n",
    "    \n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $\\sigma^2$ as:\n",
    "$$\n",
    "\\sigma^2 = (e_0 - \\rho \\cdot e_1)' (e_0 - \\rho \\cdot e_1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute full log-likelihood, including constants\n",
    "ln2pi = np.log(2.0 * np.pi)\n",
    "logll = -res.fun - (n*t) / 2.0 * ln2pi - (n*t) / 2.0\n",
    "\n",
    "u = bigy - spdot(bigx, b)\n",
    "\n",
    "# residual variance\n",
    "e_filtered = yp - spdot(xp, b)\n",
    "sig2 = (spdot(e_filtered.T, e_filtered)\n",
    "        / (n * t))\n",
    "\n",
    "# variance-covariance matrix betas\n",
    "varb = sig2 * xpxpi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Var[\\beta, \\delta, \\sigma^2] = \n",
    "\\begin{pmatrix}\n",
    "\\frac{X'X}{\\sigma^2}               &                                               &  \\\\ \n",
    "X' (I_T \\otimes \\tilde{W}) X \\beta & T \\cdot tr(\\tilde{W}^2 + \\tilde{W}'\\tilde{W}) + \\beta' X' (I_T \\otimes \\tilde{W}'\\tilde{W}) X \\beta &  \\\\ \n",
    "0                                  & \\frac{T}{\\sigma^2} tr(\\tilde{W}) & \\frac{NT}{2 \\sigma^4} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "where $\\tilde{W} = W (I_N - \\rho W)^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05069016, -0.00233537,  0.01787882,  0.        ,  0.        ],\n",
       "       [-0.00233537,  0.05401288,  0.00253422,  0.        ,  0.        ],\n",
       "       [ 0.01787882,  0.00253422,  0.0609969 ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.00027065, -0.00000071],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.00000071,  0.00304448]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance-covariance matrix lambda, sigma\n",
    "a = -lam * W\n",
    "spfill_diagonal(a, 1.0)\n",
    "ai = spinv(a)\n",
    "aTai = la.inv(spdot(a.T, a))\n",
    "wa_aw = spdot(W.T, a) + spdot(a.T, W)\n",
    "gamma = spdot(wa_aw, aTai)\n",
    "vi = la.inv(t*phi*I + aTai)\n",
    "sigma = spdot(vi, aTai)\n",
    "\n",
    "tr1 = gamma.diagonal().sum()\n",
    "tr2 = vi.diagonal().sum()\n",
    "tr3 = sigma.diagonal().sum()\n",
    "\n",
    "sigma_gamma = spdot(sigma, gamma)\n",
    "tr4 = sigma_gamma.diagonal().sum()\n",
    "\n",
    "sigma_vi = spdot(sigma, vi)\n",
    "tr5 = sigma_vi.diagonal().sum()\n",
    "\n",
    "sigma_gamma_vi = spdot(sigma_gamma, vi)\n",
    "tr6 = sigma_gamma_vi.diagonal().sum()\n",
    "\n",
    "sigma_gamma_sigma = spdot(sigma_gamma, sigma)\n",
    "tr7 = sigma_gamma_sigma.diagonal().sum()\n",
    "\n",
    "v1 = np.vstack(((t-1)/2 * tr1**2 + 1/2 * tr4**2,\n",
    "                t/(2*sig2) * tr6, \n",
    "                (t-1)/(2*sig2) * tr1 + 1/(2*sig2) * tr7))\n",
    "v2 = np.vstack((t/(2*sig2) * tr6, \n",
    "                t**2 / (2.0*sig2**2) * tr2**2, \n",
    "                t / (2.0*sig2**2) * tr5))\n",
    "v3 = np.vstack(((t-1)/(2*sig2) * tr1 + 1/(2*sig2) * tr7,\n",
    "                t / (2.0*sig2**2) * tr5,\n",
    "                1 / (2.0*sig2**2) * ((t-1)*n + tr3**2)))\n",
    "\n",
    "v = np.hstack((v1, v2, v3))\n",
    "\n",
    "vm1 = np.linalg.inv(v)\n",
    "\n",
    "# create variance matrix for beta, lambda\n",
    "vv = np.hstack((varb, np.zeros((k, 2))))\n",
    "vv1 = np.hstack(\n",
    "    (np.zeros((2, k)), vm1[:2, :2]))\n",
    "\n",
    "vm = np.vstack((vv, vv1))\n",
    "vm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: spdep\n",
      "\n",
      "Loading required package: sp\n",
      "\n",
      "Loading required package: spData\n",
      "\n",
      "To access larger datasets in this package, install the\n",
      "spDataLarge package with: `install.packages('spDataLarge',\n",
      "repos='https://nowosad.github.io/drat/', type='source')`\n",
      "\n",
      "Loading required package: sf\n",
      "\n",
      "Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 6.3.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### set options\n",
    "options(prompt = \"R> \",  continue = \"+ \", width = 70, useFancyQuotes = FALSE, warn=-1)\n",
    "\n",
    "### load library\n",
    "library(\"splm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data\n",
    "nat <- read.csv(\"data/sub_NAT.csv\", header = TRUE)\n",
    "wnat <- as.matrix(read.csv(\"data/sub_NAT_w.csv\", header = FALSE))\n",
    "## standardization\n",
    "wnat <- wnat/apply(wnat, 1, sum)\n",
    "## make it a listw\n",
    "lwnat <- mat2listw(wnat)\n",
    "\n",
    "col_order <- c(\"FIPSNO\", \"YEAR\", \"HR\", \"RD\", \"PS\")\n",
    "nat <- nat[, col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_lag = spml(HR ~ RD + PS, data=nat, listw=lwnat,\n",
    "                 model=\"random\", spatial.error = \"b\", lag=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ML panel with , random effects, spatial error correlation \n",
       "\n",
       "Call:\n",
       "spreml(formula = formula, data = data, index = index, w = listw2mat(listw), \n",
       "    w2 = listw2mat(listw2), lag = lag, errors = errors, cl = cl)\n",
       "\n",
       "Residuals:\n",
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "-10.940  -3.157  -0.869  -0.012   2.147  36.150 \n",
       "\n",
       "Error variance parameters:\n",
       "    Estimate Std. Error t-value  Pr(>|t|)    \n",
       "phi 0.304972   0.060005  5.0825 3.725e-07 ***\n",
       "rho 0.347149   0.047581  7.2960 2.964e-13 ***\n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t-value  Pr(>|t|)    \n",
       "(Intercept)  5.87150    0.22920  25.617 < 2.2e-16 ***\n",
       "RD           3.22219    0.23425  13.755 < 2.2e-16 ***\n",
       "PS           2.60396    0.24820  10.491 < 2.2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(fixed_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37858278205185986"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sig2[0][0] / phi**2 - sig2[0][0]) / 3 / sig2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "-3267.55885796687"
      ],
      "text/latex": [
       "-3267.55885796687"
      ],
      "text/markdown": [
       "-3267.55885796687"
      ],
      "text/plain": [
       "[1] -3267.559"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fixed_lag$logLik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 3 × 3 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>(Intercept)</th><th scope=col>RD</th><th scope=col>PS</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td> 0.052534769</td><td>-0.002266445</td><td>0.018073183</td></tr>\n",
       "\t<tr><th scope=row>RD</th><td>-0.002266445</td><td> 0.054873527</td><td>0.003249927</td></tr>\n",
       "\t<tr><th scope=row>PS</th><td> 0.018073183</td><td> 0.003249927</td><td>0.061604361</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 3 of type dbl\n",
       "\\begin{tabular}{r|lll}\n",
       "  & (Intercept) & RD & PS\\\\\n",
       "\\hline\n",
       "\t(Intercept) &  0.052534769 & -0.002266445 & 0.018073183\\\\\n",
       "\tRD & -0.002266445 &  0.054873527 & 0.003249927\\\\\n",
       "\tPS &  0.018073183 &  0.003249927 & 0.061604361\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 3 of type dbl\n",
       "\n",
       "| <!--/--> | (Intercept) | RD | PS |\n",
       "|---|---|---|---|\n",
       "| (Intercept) |  0.052534769 | -0.002266445 | 0.018073183 |\n",
       "| RD | -0.002266445 |  0.054873527 | 0.003249927 |\n",
       "| PS |  0.018073183 |  0.003249927 | 0.061604361 |\n",
       "\n"
      ],
      "text/plain": [
       "            (Intercept)  RD           PS         \n",
       "(Intercept)  0.052534769 -0.002266445 0.018073183\n",
       "RD          -0.002266445  0.054873527 0.003249927\n",
       "PS           0.018073183  0.003249927 0.061604361"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fixed_lag$vcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>phi</dt><dd>0.304972177618146</dd><dt>rho</dt><dd>0.34714903152487</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[phi] 0.304972177618146\n",
       "\\item[rho] 0.34714903152487\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "phi\n",
       ":   0.304972177618146rho\n",
       ":   0.34714903152487\n",
       "\n"
      ],
      "text/plain": [
       "      phi       rho \n",
       "0.3049722 0.3471490 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fixed_lag$errcomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37323359,  0.00673109,  0.15857575, -0.01069964],\n",
       "       [ 0.00673109,  0.39643321,  0.01546323, -0.004546  ],\n",
       "       [ 0.15857575,  0.01546323,  0.48536125, -0.00324211],\n",
       "       [-0.01069964, -0.004546  , -0.00324211,  0.00189414]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "np.around(vm, decimals=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leftovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_w = pd.read_excel(\"data/Spat-Sym-US.xls\", header=None)\n",
    "# df = pd.read_excel(\"data/cigardemo.xls\")\n",
    "\n",
    "# from libpysal.weights import full2W\n",
    "\n",
    "# name_y = [\"logc\"]\n",
    "# y = df[name_y].values\n",
    "\n",
    "# name_x = [\"constant\", \"logp\", \"logpn\", \"logy\"]\n",
    "# x = df[name_x].values\n",
    "\n",
    "# w = full2W(df_w.values)\n",
    "# w.transform = 'r'\n",
    "\n",
    "# method = \"full\"\n",
    "# epsilon = 0.0000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
