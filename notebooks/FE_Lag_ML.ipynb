{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Lag - Fixed Effects Panel Model\n",
    "\n",
    "This notebook introduces the Spatial Lag model for Fixed Effects Panel data. It is based on the estimation procedure outline in:\n",
    "- Anselin, Le Gallo and Jayet (2008). Spatial Panel Econometrics.\n",
    "- Elhorst (2014). Spatial Econometrics, From Cross-Sectional Data to Spatial Panels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call my local forked spreg\n",
    "import sys \n",
    "sys.path.append(r\"C:\\Users\\pablo\\Documents\\GitHub\\spreg-1\")\n",
    "import spreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from scipy import sparse as sp\n",
    "from scipy.sparse.linalg import splu as SuperLU\n",
    "from spreg.utils import inverse_prod\n",
    "from spreg.sputils import spdot, spfill_diagonal, spinv\n",
    "from libpysal import weights\n",
    "try:\n",
    "    from scipy.optimize import minimize_scalar\n",
    "    minimize_scalar_available = True\n",
    "except ImportError:\n",
    "    minimize_scalar_available = False\n",
    "    \n",
    "from spreg.panel_utils import check_panel, demean_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import libpysal to load the dataset.\n",
    "import libpysal\n",
    "from libpysal.examples import load_example\n",
    "from libpysal.weights import Queen\n",
    "\n",
    "# Open data on NCOVR US County Homicides (3085 areas).\n",
    "nat = load_example('Natregimes')\n",
    "db = libpysal.io.open(nat.get_path('natregimes.dbf'),'r')\n",
    "nat_shp = libpysal.examples.get_path(\"natregimes.shp\")\n",
    "w = Queen.from_shapefile(nat_shp)\n",
    "w.transform = 'r'\n",
    "\n",
    "name_y = ['HR70','HR80','HR90']\n",
    "y = np.array([db.by_col(name) for name in name_y]).T\n",
    "\n",
    "name_x = ['RD70','RD80','RD90','PS70','PS80','PS90']\n",
    "x = np.array([db.by_col(name) for name in name_x]).T\n",
    "\n",
    "method = \"full\"\n",
    "epsilon = 0.0000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Assuming panel is in wide format, i.e. y[:, 0] refers to T0, y[:, 1] refers to T1, etc.\n",
      "Similarly, assuming x[:, 0:T] refers to T periods of k1, x[:, T+1:2T] refers to k2, etc.\n"
     ]
    }
   ],
   "source": [
    "# Check the data structure and converts from wide to long if needed.\n",
    "bigy, bigx, name_y, name_x = check_panel(y, x, w, name_y, name_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demeaning the variables using \n",
    "$$\n",
    "y^\\ast = Q_0 y\n",
    "$$ \n",
    "\n",
    "where $Q_0 = J_T \\otimes I_N$ and $J_T = I_T - \\iota \\cdot \\iota' / t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = w.n\n",
    "t = bigy.shape[0] // n\n",
    "k = bigx.shape[1]\n",
    "# Demeaned variables\n",
    "y = demean_panel(bigy, n, t)\n",
    "x = demean_panel(bigx, n, t)\n",
    "# Big W matrix\n",
    "W = w.full()[0]\n",
    "W_nt = np.kron(np.identity(t), W)\n",
    "Wsp = w.sparse\n",
    "Wsp_nt = sp.kron(sp.identity(t), Wsp)\n",
    "# Lag dependent variable\n",
    "ylag = spdot(W_nt, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'll compute the residuals of these two regressions:\n",
    "$$\n",
    "y = X\\beta_0 + e_0\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Wy = X\\beta_1 + e_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b0, b1, e0 and e1\n",
    "xtx = spdot(x.T, x)\n",
    "xtxi = la.inv(xtx)\n",
    "xty = spdot(x.T, y)\n",
    "xtyl = spdot(x.T, ylag)\n",
    "b0 = spdot(xtxi, xty)\n",
    "b1 = spdot(xtxi, xtyl)\n",
    "e0 = y - spdot(x, b0)\n",
    "e1 = ylag - spdot(x, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, maximize the concentrated log-likehood function with respect to $\\rho$:\n",
    "$$\n",
    "L = \\frac{NT}{2} \\ln (e'_r e_r) - T \\ln | I_N - \\rho W |\n",
    "$$\n",
    "\n",
    "where $e_r = e_0 - \\rho e_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_c_loglik(rho, n, t, e0, e1, W):\n",
    "    # concentrated log-lik for lag model, no constants, brute force\n",
    "    er = e0 - rho * e1\n",
    "    sig2 = spdot(er.T, er) / (n*t)\n",
    "    nlsig2 = (n*t / 2.0) * np.log(sig2)\n",
    "    a = -rho * W\n",
    "    spfill_diagonal(a, 1.0)\n",
    "    jacob = t * np.log(np.linalg.det(a))\n",
    "    # this is the negative of the concentrated log lik for minimization\n",
    "    clik = nlsig2 - jacob\n",
    "    return clik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pablo\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:770: RuntimeWarning: Method 'bounded' does not support relative tolerance in x; defaulting to absolute tolerance.\n",
      "  \"defaulting to absolute tolerance.\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1903042364374238"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methodML = method.upper()\n",
    "res = minimize_scalar(lag_c_loglik, 0.0, bounds=(-1.0, 1.0),\n",
    "                      args=(n, t, e0, e1, W), method='bounded',\n",
    "                      tol=epsilon)\n",
    "\n",
    "rho = res.x[0][0]\n",
    "rho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate betas as:\n",
    "$$\n",
    "\\beta = \\beta_o - \\rho \\beta_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80058859],\n",
       "       [-2.60035236],\n",
       "       [ 0.19030424]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b, residuals and predicted values\n",
    "b = b0 - rho * b1\n",
    "betas = np.vstack((b, rho))   # rho added as last coefficient\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $\\sigma^2$ as:\n",
    "$$\n",
    "\\sigma^2 = (e_0 - \\rho \\cdot e_1)' (e_0 - \\rho \\cdot e_1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute full log-likelihood, including constants\n",
    "ln2pi = np.log(2.0 * np.pi)\n",
    "llik = -res.fun - (n*t) / 2.0 * ln2pi - (n*t) / 2.0\n",
    "logll = llik[0][0]\n",
    "\n",
    "# Calculate sigma2\n",
    "u = e0 - rho * e1\n",
    "sig2 = spdot(u.T, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Var[\\beta, \\delta, \\sigma^2] = \n",
    "\\left[\\begin{matrix}\n",
    "\\frac{X'X}{\\sigma^2}               &                                               &  \\\\ \n",
    "X' (I_T \\otimes \\tilde{W}) X \\beta & T \\cdot tr(\\tilde{W}^2 + \\tilde{W}'\\tilde{W}) + \\beta' X' (I_T \\otimes \\tilde{W}'\\tilde{W}) X \\beta &  \\\\ \n",
    "0                                  & \\frac{T}{\\sigma^2} tr(\\tilde{W}) & \\frac{NT}{2 \\sigma^4} \\\\\n",
    "\\end{matrix}\\right]\n",
    "$$\n",
    "\n",
    "where $\\tilde{W} = W (I_N - \\rho W)^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predy = y - u\n",
    "xb = spdot(x, b)\n",
    "predy_e = inverse_prod(\n",
    "    Wsp_nt, xb, rho, inv_method=\"power_exp\", threshold=epsilon)\n",
    "e_pred = y - predy_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.41034357e+02,  2.02069853e+02, -7.48911836e-05],\n",
       "       [ 2.02069853e+02,  2.24784043e+03,  4.30066912e-04],\n",
       "       [-7.48911836e-05,  4.30066912e-04,  2.57894113e-04]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information matrix\n",
    "a = -rho * W\n",
    "spfill_diagonal(a, 1.0)\n",
    "ai = spinv(a)\n",
    "wai = spdot(W, ai)\n",
    "tr1 = wai.diagonal().sum() #same for sparse and dense\n",
    "\n",
    "wai2 = spdot(wai, wai)\n",
    "tr2 = wai2.diagonal().sum()\n",
    "\n",
    "waiTwai = spdot(wai.T, wai)\n",
    "tr3 = waiTwai.diagonal().sum()\n",
    "\n",
    "wai_nt = np.kron(np.identity(t), wai)\n",
    "wpredy = spdot(wai_nt, xb)\n",
    "xTwpy = spdot(x.T, wpredy)\n",
    "\n",
    "waiTwai_nt = np.kron(np.identity(t), waiTwai)\n",
    "wTwpredy = spdot(waiTwai_nt, xb)\n",
    "wpyTwpy = spdot(xb.T, wTwpredy)\n",
    "\n",
    "# order of variables is beta, rho, sigma2\n",
    "v1 = np.vstack(\n",
    "    (xtx / sig2, xTwpy.T / sig2, np.zeros((1, k))))\n",
    "v2 = np.vstack(\n",
    "    (xTwpy / sig2, t*(tr2 + tr3) + wpyTwpy / sig2, t * tr1 / sig2))\n",
    "v3 = np.vstack(\n",
    "    (np.zeros((k, 1)), t * tr1 / sig2, n * t / (2.0 * sig2 ** 2)))\n",
    "\n",
    "v = np.hstack((v1, v2, v3))\n",
    "\n",
    "vm1 = la.inv(v)  # vm1 includes variance for sigma2\n",
    "vm = vm1[:-1, :-1]  # vm is for coefficients only\n",
    "vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
