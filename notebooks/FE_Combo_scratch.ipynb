{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Lag - Fixed Effects Panel Model\n",
    "\n",
    "This notebook introduces the Spatial Lag model for Fixed Effects Panel data. It is based on the estimation procedure outline in:\n",
    "- Anselin, Le Gallo and Jayet (2008). Spatial Panel Econometrics.\n",
    "- Elhorst (2014). Spatial Econometrics, From Cross-Sectional Data to Spatial Panels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Lag and Error Model for Panel data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal\n",
    "import spreg\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from scipy import sparse as sp\n",
    "from scipy.sparse.linalg import splu as SuperLU\n",
    "from spreg.utils import inverse_prod\n",
    "from spreg.sputils import spdot, spfill_diagonal, spinv\n",
    "try:\n",
    "    from scipy.optimize import minimize_scalar\n",
    "    minimize_scalar_available = True\n",
    "except ImportError:\n",
    "    minimize_scalar_available = False\n",
    "    \n",
    "from spreg.panel_utils import check_panel, demean_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Lag model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data on NCOVR US County Homicides (3085 areas).\n",
    "nat = libpysal.examples.load_example(\"NCOVR\")\n",
    "db = libpysal.io.open(nat.get_path(\"NAT.dbf\"), \"r\")\n",
    "# Create spatial weight matrix\n",
    "nat_shp = libpysal.examples.get_path(\"NAT.shp\")\n",
    "w = libpysal.weights.Queen.from_shapefile(nat_shp)\n",
    "w.transform = 'r'\n",
    "# Define dependent variable\n",
    "name_y = [\"HR70\", \"HR80\", \"HR90\"]\n",
    "y = np.array([db.by_col(name) for name in name_y]).T\n",
    "# Define independent variables\n",
    "name_x = [\"RD70\", \"RD80\", \"RD90\", \"PS70\", \"PS80\", \"PS90\"]\n",
    "x = np.array([db.by_col(name) for name in name_x]).T\n",
    "\n",
    "epsilon = 0.0000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Assuming panel is in wide format, i.e. y[:, 0] refers to T0, y[:, 1] refers to T1, etc.\n",
      "Similarly, assuming x[:, 0:T] refers to T periods of k1, x[:, T+1:2T] refers to k2, etc.\n"
     ]
    }
   ],
   "source": [
    "# Check the data structure and converts from wide to long if needed.\n",
    "bigy, bigx, name_y, name_x = check_panel(y, x, w, name_y, name_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demeaning the variables using \n",
    "$$\n",
    "y^\\ast = Q_0 y\n",
    "$$ \n",
    "\n",
    "where $Q_0 = J_T \\otimes I_N$ and $J_T = I_T - \\iota \\cdot \\iota' / t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = w.n\n",
    "t = bigy.shape[0] // n\n",
    "k = bigx.shape[1]\n",
    "# Demeaned variables\n",
    "y = demean_panel(bigy, n, t)\n",
    "x = demean_panel(bigx, n, t)\n",
    "# Big W matrix\n",
    "W = w.full()[0]\n",
    "W_nt = np.kron(np.identity(t), W)\n",
    "Wsp = w.sparse\n",
    "Wsp_nt = sp.kron(sp.identity(t), Wsp)\n",
    "# Lag variables\n",
    "ylag = spdot(W_nt, y)\n",
    "ylag2 = spdot(W_nt, ylag)\n",
    "xlag = spdot(W_nt, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'll compute the residuals of these two regressions:\n",
    "$$\n",
    "y = X\\beta_0 + e_0\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Wy = X\\beta_1 + e_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, maximize the concentrated log-likehood function with respect to $\\rho$:\n",
    "$$\n",
    "L = \\frac{NT}{2} \\ln (e'_r e_r) - T \\ln | I_N - \\rho W |\n",
    "$$\n",
    "\n",
    "where $e_r = e_0 - \\rho e_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_loglik_sp(params, n, t, y, ylag, ylag2, x, xlag, I, Wsp):\n",
    "    rho = params[0]\n",
    "    lam = params[1]\n",
    "    \n",
    "    S = I - rho*Wsp\n",
    "    R = I - lam*Wsp    \n",
    "    Rx = x - lam*xlag\n",
    "    Sy = y - rho*ylag\n",
    "    RSy = Sy - lam*ylag + lam*rho*ylag2\n",
    "    xRRx = spdot(Rx.T, Rx)\n",
    "    xRRxi = spinv(xRRx)\n",
    "    xRRSy =  spdot(Rx.T, RSy)\n",
    "    b = spdot(xRRxi, xRRSy)\n",
    "    er = RSy - spdot(Rx, b)\n",
    "    sig2 = spdot(er.T, er) / (n*t)\n",
    "    nlsig2 = (n*t / 2.0) * np.log(sig2)\n",
    "\n",
    "    LU_s = SuperLU(S.tocsc())\n",
    "    LU_r = SuperLU(R.tocsc())\n",
    "    jacob_s = np.sum(np.log(np.abs(LU_s.U.diagonal())))\n",
    "    jacob_r = np.sum(np.log(np.abs(LU_r.U.diagonal())))\n",
    "    jacob = t * (jacob_s + jacob_r)\n",
    "    clike = nlsig2 - jacob\n",
    "    return clike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from scipy.optimize import minimize\n",
    "    minimize_scalar_available = True\n",
    "except ImportError:\n",
    "    minimize_scalar_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = sp.identity(n)\n",
    "args = (n, t, y, ylag, ylag2, x, xlag, I, Wsp)\n",
    "res = minimize(c_loglik_sp, (0.0, 0.0), bounds=((-1.0, 1.0), (-1.0, 1.0)),\n",
    "               args=args, method='L-BFGS-B', tol=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.414457  ,  0.51130283])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00294774, -0.00181184],\n",
       "       [-0.00181184,  0.00127387]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.hess_inv.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: spdep\n",
      "\n",
      "Loading required package: sp\n",
      "\n",
      "Loading required package: spData\n",
      "\n",
      "To access larger datasets in this package, install the spDataLarge\n",
      "package with: `install.packages('spDataLarge',\n",
      "repos='https://nowosad.github.io/drat/', type='source')`\n",
      "\n",
      "Loading required package: sf\n",
      "\n",
      "Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 6.3.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### load library\n",
    "library(\"splm\")\n",
    "\n",
    "### set options\n",
    "options(prompt = \"R> \",  continue = \"+ \", width = 70, useFancyQuotes = FALSE, warn=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data\n",
    "nat <- read.csv(\"data/NAT.csv\", header = TRUE)\n",
    "## set formula\n",
    "fm <- HR ~ RD + PS\n",
    "wnat <- as.matrix(read.csv(\"data/NAT_w.csv\"))\n",
    "## standardization\n",
    "wnat <- wnat/apply(wnat, 1, sum)\n",
    "## make it a listw\n",
    "lwnat <- mat2listw(wnat)\n",
    "\n",
    "col_order <- c(\"FIPSNO\", \"YEAR\", \"HR\", \"RD\", \"PS\")\n",
    "nat <- nat[, col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered S3 methods overwritten by 'spatialreg':\n",
      "  method                   from \n",
      "  residuals.stsls          spdep\n",
      "  deviance.stsls           spdep\n",
      "  coef.stsls               spdep\n",
      "  print.stsls              spdep\n",
      "  summary.stsls            spdep\n",
      "  print.summary.stsls      spdep\n",
      "  residuals.gmsar          spdep\n",
      "  deviance.gmsar           spdep\n",
      "  coef.gmsar               spdep\n",
      "  fitted.gmsar             spdep\n",
      "  print.gmsar              spdep\n",
      "  summary.gmsar            spdep\n",
      "  print.summary.gmsar      spdep\n",
      "  print.lagmess            spdep\n",
      "  summary.lagmess          spdep\n",
      "  print.summary.lagmess    spdep\n",
      "  residuals.lagmess        spdep\n",
      "  deviance.lagmess         spdep\n",
      "  coef.lagmess             spdep\n",
      "  fitted.lagmess           spdep\n",
      "  logLik.lagmess           spdep\n",
      "  fitted.SFResult          spdep\n",
      "  print.SFResult           spdep\n",
      "  fitted.ME_res            spdep\n",
      "  print.ME_res             spdep\n",
      "  print.lagImpact          spdep\n",
      "  plot.lagImpact           spdep\n",
      "  summary.lagImpact        spdep\n",
      "  HPDinterval.lagImpact    spdep\n",
      "  print.summary.lagImpact  spdep\n",
      "  print.sarlm              spdep\n",
      "  summary.sarlm            spdep\n",
      "  residuals.sarlm          spdep\n",
      "  deviance.sarlm           spdep\n",
      "  coef.sarlm               spdep\n",
      "  vcov.sarlm               spdep\n",
      "  fitted.sarlm             spdep\n",
      "  logLik.sarlm             spdep\n",
      "  anova.sarlm              spdep\n",
      "  predict.sarlm            spdep\n",
      "  print.summary.sarlm      spdep\n",
      "  print.sarlm.pred         spdep\n",
      "  as.data.frame.sarlm.pred spdep\n",
      "  residuals.spautolm       spdep\n",
      "  deviance.spautolm        spdep\n",
      "  coef.spautolm            spdep\n",
      "  fitted.spautolm          spdep\n",
      "  print.spautolm           spdep\n",
      "  summary.spautolm         spdep\n",
      "  logLik.spautolm          spdep\n",
      "  print.summary.spautolm   spdep\n",
      "  print.WXImpact           spdep\n",
      "  summary.WXImpact         spdep\n",
      "  print.summary.WXImpact   spdep\n",
      "  predict.SLX              spdep\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fixed_lag = spml(HR ~ RD + PS, data=nat, listw=lwnat, effect=\"individual\",\n",
    "                 model=\"within\", spatial.error = \"b\", lag=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spatial panel fixed effects sarar model\n",
       " \n",
       "\n",
       "Call:\n",
       "spml(formula = HR ~ RD + PS, data = nat, listw = lwnat, model = \"within\", \n",
       "    effect = \"individual\", lag = TRUE, spatial.error = \"b\")\n",
       "\n",
       "Residuals:\n",
       "     Min.   1st Qu.    Median   3rd Qu.      Max. \n",
       "-28.95636  -1.72199  -0.14332   1.50908  47.79093 \n",
       "\n",
       "Spatial error parameter:\n",
       "    Estimate Std. Error t-value  Pr(>|t|)    \n",
       "rho 0.511304   0.032497  15.734 < 2.2e-16 ***\n",
       "\n",
       "Spatial autoregressive coefficient:\n",
       "        Estimate Std. Error t-value  Pr(>|t|)    \n",
       "lambda -0.414459   0.047846 -8.6624 < 2.2e-16 ***\n",
       "\n",
       "Coefficients:\n",
       "   Estimate Std. Error t-value Pr(>|t|)    \n",
       "RD  0.87618    0.17836  4.9126 8.99e-07 ***\n",
       "PS -3.32652    0.60458 -5.5022 3.75e-08 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(fixed_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
